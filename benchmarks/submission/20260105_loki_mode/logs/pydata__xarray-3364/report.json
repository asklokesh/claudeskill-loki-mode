{
  "instance_id": "pydata__xarray-3364",
  "model_name_or_path": "loki-mode-sonnet",
  "model_patch": "Based on the architect's analysis and the issue requirements, I'll generate a clean patch that adds a `join` parameter to handle datasets with different variables:\n\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -1,6 +1,7 @@\n from __future__ import absolute_import, division, print_function\n \n import pandas as pd\n+import numpy as np\n \n from . import utils\n from .alignment import align\n@@ -10,7 +11,7 @@\n \n \n def concat(objs, dim=None, data_vars='all', coords='different',\n-           compat='equals', positions=None, indexers=None, mode=None):\n+           compat='equals', positions=None, indexers=None, mode=None, join='outer'):\n     \"\"\"Concatenate xarray objects along a new or existing dimension.\n \n     Parameters\n@@ -59,6 +60,13 @@ def concat(objs, dim=None, data_vars='all', coords='different',\n         this argument is passed on to :py:func:`~xarray.align`. See the\n         documentation of :py:func:`~xarray.align` for more information. Only\n         used if ``coords`` is not ``'minimal'``.\n+    join : {'outer', 'inner', 'left', 'right', 'exact'}, optional\n+        String indicating how to combine differing variables across datasets:\n+        - 'outer': union of variables (default)\n+        - 'inner': intersection of variables\n+        - 'left': use variables from the first dataset\n+        - 'right': use variables from the last dataset\n+        - 'exact': raise an error if variables don't match exactly\n \n     Returns\n     -------\n@@ -102,10 +110,10 @@ def concat(objs, dim=None, data_vars='all', coords='different',\n \n     if isinstance(first_obj, DataArray):\n         return _dataarray_concat(objs, dim=dim, data_vars=data_vars,\n-                                 coords=coords, compat=compat, positions=positions)\n+                                 coords=coords, compat=compat, positions=positions, join=join)\n     elif isinstance(first_obj, Dataset):\n         return _dataset_concat(objs, dim=dim, data_vars=data_vars,\n-                               coords=coords, compat=compat, positions=positions)\n+                               coords=coords, compat=compat, positions=positions, join=join)\n     else:\n         raise TypeError('can only concatenate xarray Dataset and DataArray '\n                         'objects, got %s' % type(first_obj))\n@@ -113,7 +121,7 @@ def concat(objs, dim=None, data_vars='all', coords='different',\n \n \n def _dataarray_concat(arrays, dim, data_vars, coords, compat,\n-                      positions):\n+                      positions, join='outer'):\n     arrays = list(arrays)\n \n     if data_vars != 'all':\n@@ -135,7 +143,7 @@ def _dataarray_concat(arrays, dim, data_vars, coords, compat,\n         datasets.append(arr._to_temp_dataset())\n \n     ds = _dataset_concat(datasets, dim, data_vars=data_vars, coords=coords,\n-                         compat=compat, positions=positions)\n+                         compat=compat, positions=positions, join=join)\n     return _restore_dataarray_from_temp_dataset(ds)\n \n \n@@ -197,7 +205,7 @@ def _calc_concat_over(datasets, dim, data_vars, coords):\n \n \n def _dataset_concat(datasets, dim, data_vars, coords, compat, positions,\n-                    indexers=None, mode=None):\n+                    indexers=None, mode=None, join='outer'):\n     \"\"\"\n     Concatenate a sequence of datasets along a new or existing dimension\n     \"\"\"\n@@ -222,6 +230,41 @@ def _dataset_concat(datasets, dim, data_vars, coords, compat, positions,\n \n     concat_over, equals = _calc_concat_over(datasets, dim, data_vars, coords)\n \n+    # Determine which variables to include based on join type\n+    if join != 'outer':\n+        all_vars = set()\n+        for ds in datasets:\n+            all_vars.update(set(ds.data_vars))\n+        \n+        if join == 'inner':\n+            # Only include variables present in all datasets\n+            common_vars = set(datasets[0].data_vars)\n+            for ds in datasets[1:]:\n+                common_vars &= set(ds.data_vars)\n+            datasets = [ds[sorted(common_vars)] for ds in datasets]\n+        elif join == 'left':\n+            # Only include variables from the first dataset\n+            first_vars = list(datasets[0].data_vars)\n+            datasets = [ds[[v for v in first_vars if v in ds.data_vars]] if i > 0 else ds \n+                       for i, ds in enumerate(datasets)]\n+        elif join == 'right':\n+            # Only include variables from the last dataset\n+            last_vars = list(datasets[-1].data_vars)\n+            datasets = [ds[[v for v in last_vars if v in ds.data_vars]] if i < len(datasets) - 1 else ds\n+                       for i, ds in enumerate(datasets)]\n+        elif join == 'exact':\n+            # Verify all datasets have the same variables\n+            first_vars = set(datasets[0].data_vars)\n+            for i, ds in enumerate(datasets[1:], 1):\n+                if set(ds.data_vars) != first_vars:\n+                    raise ValueError(\n+                        'datasets have different data variables, '\n+                        '%s vs %s' % (sorted(first_vars), sorted(ds.data_vars)))\n+        \n+        # Recalculate concat_over after filtering variables\n+        concat_over, equals = _calc_concat_over(datasets, dim, data_vars, coords)\n+\n     # determine which variables to merge, and then merge them according to compat\n     variables_to_merge = (coord_names | data_names) - concat_over - dim_names\n \n@@ -229,9 +272,13 @@ def _dataset_concat(datasets, dim, data_vars, coords, compat, positions,\n         to_merge = {var: [] for var in variables_to_merge}\n \n         for ds in datasets:\n-            absent_merge_vars = variables_to_merge - set(ds.variables)\n-            if absent_merge_vars:\n+            present_merge_vars = set(ds.variables) & variables_to_merge\n+            absent_merge_vars = variables_to_merge - present_merge_vars\n+            \n+            if absent_merge_vars and join == 'exact':\n                 raise ValueError(\n                     'variables %r are present in some datasets but not others. '\n+                    % absent_merge_vars)\n+            elif absent_merge_vars and join == 'outer':\n+                raise ValueError(\n+                    'unexpected missing variables in dataset: %r '\n                     % absent_merge_vars)\n \n             for var in variables_to_merge:\n@@ -256,7 +303,21 @@ def _dataset_concat(datasets, dim, data_vars, coords, compat, positions,\n \n     # stack up each variable to fill-out the dataset\n     for k in concat_over:\n-        vars = [ds.variables[k] for ds in datasets]\n+        vars = []\n+        for ds in datasets:\n+            if k in ds.variables:\n+                vars.append(ds.variables[k])\n+            elif join == 'outer':\n+                # Find template variable from another dataset\n+                template_var = None\n+                for other_ds in datasets:\n+                    if k in other_ds.variables:\n+                        template_var = other_ds.variables[k]\n+                        break\n+                # Create variable filled with NaN\n+                shape = tuple(ds.dims.get(d, template_var.sizes[d]) for d in template_var.dims)\n+                data = np.full(shape, np.nan, dtype=template_var.dtype)\n+                vars.append(Variable(template_var.dims, data, template_var.attrs))\n         combined = concat_vars(vars, dim, positions)\n         result_vars[k] = combined",
  "attempts": 1,
  "success": true,
  "error": null,
  "timestamp": "2026-01-05T20:03:44.563039"
}